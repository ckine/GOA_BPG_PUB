<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Hardware | _main.knit</title>
  <meta name="description" content="" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Hardware | _main.knit" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Hardware | _main.knit" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="intro.html"/>
<link rel="next" href="geo_accuracy.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Best Practice Guide to Acquisition of 3D Imagery from RPAS</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Best Practice Guide to Acquisition of 3D Imagery from RPAS</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#cite_report"><i class="fa fa-check"></i>How to cite this report:</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="contents.html"><a href="contents.html"><i class="fa fa-check"></i>Contents</a></li>
<li class="chapter" data-level="" data-path="glossary.html"><a href="glossary.html"><i class="fa fa-check"></i>Glossary</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="hardware.html"><a href="hardware.html"><i class="fa fa-check"></i><b>2</b> Hardware</a>
<ul>
<li class="chapter" data-level="2.1" data-path="hardware.html"><a href="hardware.html#RPA"><i class="fa fa-check"></i><b>2.1</b> Remotely Piloted Aircraft (RPA)</a></li>
<li class="chapter" data-level="2.2" data-path="hardware.html"><a href="hardware.html#sensors"><i class="fa fa-check"></i><b>2.2</b> Imaging Sensors</a></li>
<li class="chapter" data-level="2.3" data-path="hardware.html"><a href="hardware.html#other_h"><i class="fa fa-check"></i><b>2.3</b> Other Hardware Considerations</a></li>
<li class="chapter" data-level="2.4" data-path="hardware.html"><a href="hardware.html#workstation"><i class="fa fa-check"></i><b>2.4</b> Workstation</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="geo_accuracy.html"><a href="geo_accuracy.html"><i class="fa fa-check"></i><b>3</b> Geometric Accuracy</a>
<ul>
<li class="chapter" data-level="3.1" data-path="geo_accuracy.html"><a href="geo_accuracy.html#GCP"><i class="fa fa-check"></i><b>3.1</b> Ground Control Points (GCP)</a></li>
<li class="chapter" data-level="3.2" data-path="geo_accuracy.html"><a href="geo_accuracy.html#RTK_wf"><i class="fa fa-check"></i><b>3.2</b> Real-Time Kinematic (RTK) Workflows</a></li>
<li class="chapter" data-level="3.3" data-path="geo_accuracy.html"><a href="geo_accuracy.html#PPK_wf"><i class="fa fa-check"></i><b>3.3</b> Post-Processing Kinematic Workflows (PPK)</a></li>
<li class="chapter" data-level="3.4" data-path="geo_accuracy.html"><a href="geo_accuracy.html#use_case"><i class="fa fa-check"></i><b>3.4</b> Determining Use-Case</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="planning.html"><a href="planning.html"><i class="fa fa-check"></i><b>4</b> Acquisition Planning</a>
<ul>
<li class="chapter" data-level="4.1" data-path="planning.html"><a href="planning.html#takeoff"><i class="fa fa-check"></i><b>4.1</b> Takeoff Sites</a></li>
<li class="chapter" data-level="4.2" data-path="planning.html"><a href="planning.html#flight_plan"><i class="fa fa-check"></i><b>4.2</b> Flight Planning Software</a></li>
<li class="chapter" data-level="4.3" data-path="planning.html"><a href="planning.html#timing"><i class="fa fa-check"></i><b>4.3</b> Timing</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="DPP.html"><a href="DPP.html"><i class="fa fa-check"></i><b>5</b> Digital Photogrammetric Processing</a>
<ul>
<li class="chapter" data-level="5.1" data-path="DPP.html"><a href="DPP.html#software"><i class="fa fa-check"></i><b>5.1</b> Software Choices</a></li>
<li class="chapter" data-level="5.2" data-path="DPP.html"><a href="DPP.html#agisoft_wf"><i class="fa fa-check"></i><b>5.2</b> Agisoft Workflow Walk-Throughs</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="DPP.html"><a href="DPP.html#imagery_org"><i class="fa fa-check"></i><b>5.2.1</b> Imagery Organization</a></li>
<li class="chapter" data-level="5.2.2" data-path="DPP.html"><a href="DPP.html#image_filt"><i class="fa fa-check"></i><b>5.2.2</b> Image filtering</a></li>
<li class="chapter" data-level="5.2.3" data-path="DPP.html"><a href="DPP.html#image_align"><i class="fa fa-check"></i><b>5.2.3</b> Image Alignment</a></li>
<li class="chapter" data-level="5.2.4" data-path="DPP.html"><a href="DPP.html#cloud_filt"><i class="fa fa-check"></i><b>5.2.4</b> Sparse Cloud Filtering</a></li>
<li class="chapter" data-level="5.2.5" data-path="DPP.html"><a href="DPP.html#map_gen"><i class="fa fa-check"></i><b>5.2.5</b> Depth Map Generation</a></li>
<li class="chapter" data-level="5.2.6" data-path="DPP.html"><a href="DPP.html#map_filt"><i class="fa fa-check"></i><b>5.2.6</b> Depth Map Filtering</a></li>
<li class="chapter" data-level="5.2.7" data-path="DPP.html"><a href="DPP.html#micasense"><i class="fa fa-check"></i><b>5.2.7</b> Multispectral (MicaSense)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="PPP.html"><a href="PPP.html"><i class="fa fa-check"></i><b>6</b> Photogrammetric Post-Processing</a>
<ul>
<li class="chapter" data-level="6.1" data-path="PPP.html"><a href="PPP.html#software_PPP"><i class="fa fa-check"></i><b>6.1</b> Software choices</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="PPP.html"><a href="PPP.html#LAStools"><i class="fa fa-check"></i><b>6.1.1</b> LAStools</a></li>
<li class="chapter" data-level="6.1.2" data-path="PPP.html"><a href="PPP.html#lidR"><i class="fa fa-check"></i><b>6.1.2</b> lidR</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="PPP.html"><a href="PPP.html#wf_script"><i class="fa fa-check"></i><b>6.2</b> Workflows/Scripting</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="PPP.html"><a href="PPP.html#comp"><i class="fa fa-check"></i><b>6.2.1</b> Compression</a></li>
<li class="chapter" data-level="6.2.2" data-path="PPP.html"><a href="PPP.html#tiling"><i class="fa fa-check"></i><b>6.2.2</b> Tiling and Buffering</a></li>
<li class="chapter" data-level="6.2.3" data-path="PPP.html"><a href="PPP.html#noise_filt"><i class="fa fa-check"></i><b>6.2.3</b> Noise filtering</a></li>
<li class="chapter" data-level="6.2.4" data-path="PPP.html"><a href="PPP.html#class"><i class="fa fa-check"></i><b>6.2.4</b> Classification</a></li>
<li class="chapter" data-level="6.2.5" data-path="PPP.html"><a href="PPP.html#normal"><i class="fa fa-check"></i><b>6.2.5</b> Normalization</a></li>
<li class="chapter" data-level="6.2.6" data-path="PPP.html"><a href="PPP.html#PC_normal"><i class="fa fa-check"></i><b>6.2.6</b> Point Cloud Normalization with Co-Occurring LiDAR</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="PPP.html"><a href="PPP.html#data"><i class="fa fa-check"></i><b>6.3</b> Standard Data Products</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="PPP.html"><a href="PPP.html#DTM"><i class="fa fa-check"></i><b>6.3.1</b> Digital Terrain Model/Digital Elevation Model</a></li>
<li class="chapter" data-level="6.3.2" data-path="PPP.html"><a href="PPP.html#CHM"><i class="fa fa-check"></i><b>6.3.2</b> Canopy Height Model</a></li>
<li class="chapter" data-level="6.3.3" data-path="PPP.html"><a href="PPP.html#metrics"><i class="fa fa-check"></i><b>6.3.3</b> Standardized Metrics</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="field_data.html"><a href="field_data.html"><i class="fa fa-check"></i><b>7</b> Field Data Collection</a>
<ul>
<li class="chapter" data-level="7.1" data-path="field_data.html"><a href="field_data.html#stem_map"><i class="fa fa-check"></i><b>7.1</b> Stem Mapping Method 1: Distance and Azimuth</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="field_data.html"><a href="field_data.html#instrument"><i class="fa fa-check"></i><b>7.1.1</b> Instrument Calibration</a></li>
<li class="chapter" data-level="7.1.2" data-path="field_data.html"><a href="field_data.html#methods"><i class="fa fa-check"></i><b>7.1.2</b> Methods</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="field_data.html"><a href="field_data.html#stem_map_image"><i class="fa fa-check"></i><b>7.2</b> Stem Mapping Method 2: Direct-to-Image</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i><b>8</b> Selected Bibliography of Relevant University of British Columbia Publications</a></li>
<li class="chapter" data-level="9" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>9</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hardware" class="section level1" number="2">
<h1><span class="header-section-number">Chapter 2</span> Hardware</h1>
<div id="RPA" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Remotely Piloted Aircraft (RPA)</h2>
<p>Remotely Piloted Aircraft (RPA) are commonly known to as unmanned aerial vehicles (UAV) or simply, drones. The term RPA refers only to aircraft, whereas the term Remotely Piloted Aircraft Systems (RPAS) refers to RPA in addition to all components of data collection and processing, including any operating personnel <span class="citation">(<strong>RPAS-Governance-Committee2020Remotely?</strong>)</span>. Generally, there are two fundamental types of RPA: fixed-wing and rotary-wing. While the rest of this report covers only rotary-wing RPA, fixed-wing RPA are included in this section for completeness. Fixed-wing RPA mimic the design of a conventional airplane, consisting of a single rigid wing with an engineered aerofoil, one or multiple propellers, and flight control surfaces which adjust the roll, pitch and yaw of the aircraft. Fixed-wing RPA require specific runways, launchers (depending on the RPA model either mechanical or human thrown), or specialized vertical take-off and landing systems to become airborne. Like conventional airplanes, fixed-wing RPA must remain in a constant forward motion once they are airborne. Rotary-wing RPA are lifted and flown using rotor blades which are attached to a central mast. Air is forced downwards through the rotors, creating a vertical lift.</p>
<p>Fixed-wing and rotary-wing RPA each have their own advantages and disadvantages. Relative to rotary-wing RPA, fixed-wing RPA are more aerodynamic and have lower power requirements. These qualities facilitate greater flight speeds and longer battery life, making fixed-wing RPA ideal for large-scale mapping and surveying <span class="citation">(<strong>Nex2014UAV?</strong>)</span>. Rotary-wing RPA have a high degree of maneuverability and allow more customization considering payloads (i.e. gimbals and sensors). The ability to hover makes them very suitable for inspection-related tasks where they need to fly around specific objects, and allows for operation in confined spaces. Above all, the operation of rotary-wing RPA is safer as they are easier to pilot manually, and flights can be interrupted by having the aircraft hover or rapidly return-to-home. Fixed-wing RPA, on the other hand, cannot hover and cameras need to be integrated in the aircraft’s body, limiting the degree to which payloads may be customized. Currently, the acquisition costs associated with fixed-wing RPA are higher than with rotary-wing RPA, though there is likely a trade-off with shorter image acquisition times.</p>
</div>
<div id="sensors" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Imaging Sensors</h2>
<p>The two main sensor types relevant for forestry and environmental monitoring applications are conventional red-green-blue (RGB) (also called visible-light) and multispectral cameras. RGB cameras capture light in three spectral bands, which correspond to the frequencies of red, green, and blue light. By the strictest definition of the word, multispectral refers to multiple regions of the electromagnetic spectrum, which by definition includes RGB wavelengths. However, multispectral is used to refer to sensors which, in addition to capturing light in conventional RGB bands, capture light at longer non-visible wavelengths (most commonly in the near-infrared region of the electromagnetic spectrum). These non-visible wavelengths are reflected off surfaces with less energy than visible wavelengths, resulting in coarser spatial resolution of non-visible image channels compared with visible light channels. Furthermore, multispectral sensors like the MicaSense-RedEdge collect spectral data in very narrow bands relative to common RGB sensors. This too has the effect of reducing spatial resolution; the reduction in bandwidth of these more spectrally sensitive sensors results in a weaker signal which necessitates larger pixel sizes (ground sampling distances) during acquisition. Generally speaking, the pixel sizes from sensors like the MicaSense are two to three times larger than those of conventional RGB sensors.</p>
<p>RGB cameras are by far the most commonly available RPA sensors, and are typically integrated into the RPA (the DJI Phantom 4 Pro, for example), especially in the case of fixed-wing RPA. Despite their relative simplicity and lower costs, RGB sensors are perfectly suitable for producing high quality orthomosaics and DAP point clouds. In contrast to the Phantom 4 Pro and most fixed-wing models, large rotary-wing RPA (such as the DJI Matrice 300) allow for a large range of cameras to be mounted.</p>
<table>
<caption><strong>Table 1.</strong> Comparison of a common and high-end rotary-wing RPAS for data collection over a 40 ha area at a ground sampling distance (GSD) of 3 cm with 90% forward and 85% side overlap. Battery sets used refers to the estimated number of times an operator would need to swap in new batteries to complete the acquisition. Total acquisition time includes time expended during battery swaps. All flight parameters were calculated in Map Pilot Pro <span class="citation">(<strong>Drones-Made-Easy0Map?</strong>)</span>.</caption>
<colgroup>
<col width="14%" />
<col width="41%" />
<col width="43%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Class</strong></th>
<th align="center"><strong>Common Setup</strong></th>
<th align="center"><strong>High-end setup</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Drone model</td>
<td align="center">Phantom 4 RTK</td>
<td align="center">Matrice 300 RTK</td>
</tr>
<tr class="even">
<td>Camera model</td>
<td align="center">Integrated camera</td>
<td align="center">Zenmuse P1</td>
</tr>
<tr class="odd">
<td>Platform Cost</td>
<td align="center"><span>$</span>CAD 11,600</td>
<td align="center"><span>$</span>CAD 15,220</td>
</tr>
<tr class="even">
<td>Sensor Cost</td>
<td align="center">-</td>
<td align="center">$CAD 9,130</td>
</tr>
<tr class="odd">
<td>X Resolution (pixels)</td>
<td align="center">4864</td>
<td align="center">8192</td>
</tr>
<tr class="even">
<td>Y Resolution (Pixels)</td>
<td align="center">3648</td>
<td align="center">5460</td>
</tr>
<tr class="odd">
<td>Pixel Pitch (μm)</td>
<td align="center">2.4</td>
<td align="center">4.4</td>
</tr>
<tr class="even">
<td>Focal Length (mm)</td>
<td align="center">8.8</td>
<td align="center">24</td>
</tr>
<tr class="odd">
<td>Max image rate (s/frame)</td>
<td align="center">2</td>
<td align="center">0.7</td>
</tr>
<tr class="even">
<td>Flying Speed</td>
<td align="center">5.4 m/s</td>
<td align="center">10 m/s</td>
</tr>
<tr class="odd">
<td>Flying Altitude</td>
<td align="center">109 m</td>
<td align="center">167 m (SFOC needed)</td>
</tr>
<tr class="even">
<td>Max battery time</td>
<td align="center">25 min</td>
<td align="center">35 min</td>
</tr>
<tr class="odd">
<td>Images</td>
<td align="center">6,203</td>
<td align="center">5,761</td>
</tr>
<tr class="even">
<td>Memory</td>
<td align="center">13.1 GB</td>
<td align="center">11.6 GB</td>
</tr>
<tr class="odd">
<td>Total acquisition time</td>
<td align="center">85 min</td>
<td align="center">24 min</td>
</tr>
<tr class="even">
<td>Battery sets used</td>
<td align="center">4</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<p>Due to recent technological advancements, there is a wide range of commercially available RPA sensors available today. Higher priced cameras generally offer faster image capturing rates as a result of improved shutter and memory writing speeds, as well as improved image resolution. Advanced gimbals have improved sensor stability and can also facilitate the capture of imagery at oblique angles. Meanwhile, improvements to sensor durability and water resistance have been made for newer sensors. Image acquisition time can be greatly reduced with a combination of higher image resolution and faster image capturing, allowing more advanced RPA to fly higher and faster, while maintaining the same ground sampling distance (GSD) as older sensors (Table 1). When flying at higher altitudes, the sensor’s field of view is increased, which can improve success and speed of photogrammetric processing.</p>
<p>The extent to which sensors can be integrated with RPAS varies. Newer cameras and RPA can be combined into a single integrated system, wherein the RPA provides power to the camera, triggers the camera, sends live footage to the ground control station, and provides positioning data to the camera. Some camera models, particularly multispectral cameras, may not support full integration with all RPA models and will use their own built-in global positioning system (GPS) or global navigation satellite system (GNSS) receiver and triggering mechanism. RPA-sensor integration compatibility should be considered as this can improve ease of use and can be important when combining various spatial datasets and DAP acquisitions.</p>
</div>
<div id="other_h" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Other Hardware Considerations</h2>
<p>The number of batteries required for data acquisition should be considered. This is a function of the RPA model (i.e. battery capacity) and planned acquisition duration. Battery consumption will vary due to factors such as temperature and wind speed, and should be planned for accordingly. A generator, as well as additional charging stations, will likely be required to operate an RPAS continuously throughout the day.</p>
<p>Hundreds of gigabytes of storage will likely be needed to support continuous acquisitions throughout the day. As such, extra memory cards and hard drives should be kept on hand. Reading and writing speed are particularly important when working with large datasets, thus the use of solid state drives (SSD) as well as modern connectors such as USB-C and Thunderbolt is recommended.</p>
<p>Data for forestry and environmental monitoring applications will often be acquired in remote locations. It is important to have an appropriate vehicle that can be used on forest service roads. Access points may also be used by oil and gas operations. For this reason, a two-way radio is recommended for communication with other vehicles you may share the road with. Additionally, having a mobile landing and take-off pad is useful for keeping dust and mud away from equipment.</p>
</div>
<div id="workstation" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> Workstation</h2>
<p>In addition to RPAS hardware, a high-functioning computer workstation is required to retrieve data from RPA, process the data using photogrammetric software, and perform subsequent processing on photogrammetric products such as orthomosaics and photogrammetric point clouds. Photogrammetric processing is a task that demands high computational power, memory and storage. The amount of computational resources required depends on the extent of the study area, GSD, image overlap, the use of high accuracy settings, and whether imagery from multiple sensors is used. In the case of multispectral cameras, each band is captured simultaneously by a specialized sensor, which functions as an individual camera for the purpose of photogrammetric processing.</p>
<p>The most resource-intensive stages of photogrammetric processing benefit from high-end graphics processing units (GPU), otherwise known as graphics cards. For example, the company behind the photogrammetric software, Agisoft Metashape, recommends the use of: 1) at least one GPU with upwards of 1920 parallel processors (known as CUDA cores for Nvidia products or Stream Processors for AMD products), 2) a multi-core central processing unit (CPU) with upwards of 6 cores, 3) a clock speed of 3 gigahertz (GHz), and 4) upwards of 64 gigabytes of random access memory (RAM) <span class="citation">(<strong>Agisoft-LLC0Agisoft?</strong>)</span>. Benchmark tests, available through <span class="citation">(<strong>George2019Metashape?</strong>)</span>, and forums of photogrammetric software providers can help a user select the appropriate hardware configuration.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="intro.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="geo_accuracy.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/03_Hardware.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
